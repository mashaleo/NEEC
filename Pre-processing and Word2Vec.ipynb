{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masha\\AppData\\Local\\Temp\\ipykernel_8204\\1080375821.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Score'] = positiveNegative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\masha\\git\\NEEC\\Reviews.csv\")\n",
    "print(data.head())\n",
    "\n",
    "# Group by 'ProfileName' and count the occurrences\n",
    "profile_counts = data['ProfileName'].value_counts()\n",
    "\n",
    "# Get the profile names where the count is less than or equal to 50\n",
    "valid_profiles = profile_counts[profile_counts >= 100].index\n",
    "\n",
    "\n",
    "# Filter the DataFrame to keep only the rows where the 'ProfileName' is in the valid_profiles list\n",
    "filtered_df = data[data['ProfileName'].isin(valid_profiles)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change score value to \"poitive\" or \"negative\"\n",
    "def classify_score(score):\n",
    "    if score < 3:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masha\\AppData\\Local\\Temp\\ipykernel_8204\\1810857156.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Score'] = positiveNegative\n"
     ]
    }
   ],
   "source": [
    "#update score\n",
    "actualScore = filtered_df['Score']\n",
    "positiveNegative = actualScore.map(classify_score)\n",
    "filtered_df['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             Id   ProductId          UserId                       ProfileName  \\\n",
       "14          15  B001GVISJM  A2MUGFV2TDQ47K               Lynrie \"Oh HELL no\"   \n",
       "46          47  B001EO5QW8   AQLL2R1PPR46X                     grumpyrainbow   \n",
       "74          75  B001EPPI84  A3Q0IDQ03S0158                               Jen   \n",
       "109        110  B001REEG6C   AY12DBB0U420B                     Gary Peterson   \n",
       "136        137  B002SRYRE8  A198FU6P1BVUNZ                             Sarah   \n",
       "...        ...         ...             ...                               ...   \n",
       "568261  568262  B00374ZKQ0  A2GEZJHBV92EVR                      History buff   \n",
       "568331  568332  B001BOAOLY  A36MP37DITBU6F  Enchanted  In  Dixie \"Enchanted\"   \n",
       "568345  568346  B004BRECPW   AG3K28ZL7BR8M                               Jen   \n",
       "568361  568362  B000LKVRQA  A1YUL9PCJR3JTY   O. Brown \"Ms. O. Khannah-Brown\"   \n",
       "568367  568368  B000LKVRQA   AYB4ELCS5AM8P               John B. Goode \"JBG\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "14                         4                       5  positive  1268352000   \n",
       "46                         0                       0  positive  1192752000   \n",
       "74                         0                       0  negative  1287705600   \n",
       "109                        0                       0  positive  1316390400   \n",
       "136                        0                       0  positive  1349740800   \n",
       "...                      ...                     ...       ...         ...   \n",
       "568261                     0                       0  positive  1345075200   \n",
       "568331                     6                       6  positive  1244419200   \n",
       "568345                     0                       0  positive  1324771200   \n",
       "568361                     1                       1  positive  1282608000   \n",
       "568367                     0                       0  positive  1313539200   \n",
       "\n",
       "                                                  Summary  \\\n",
       "14                           Strawberry Twizzlers - Yummy   \n",
       "46                                                   good   \n",
       "74                                        nothing special   \n",
       "109                          My Idea of a Good Diet Food.   \n",
       "136                      Tastes awesome & looks beautiful   \n",
       "...                                                   ...   \n",
       "568261                    Very good alternative to sugar.   \n",
       "568331  GREAT ORGANIC Honey flavor Hard candy. Great c...   \n",
       "568345                                         Delicious!   \n",
       "568361             An Earl Grey Tea That Won't Disappoint   \n",
       "568367                                         Excellent!   \n",
       "\n",
       "                                                     Text  \n",
       "14      The Strawberry Twizzlers are my guilty pleasur...  \n",
       "46      Good oatmeal.  I like the apple cinnamon the b...  \n",
       "74      It is okay.  I would not go out of my way to b...  \n",
       "109     I'm presently on a diet and I was at my Fresh ...  \n",
       "136     The BEST investment I've ever made for ginger....  \n",
       "...                                                   ...  \n",
       "568261  I have tried many of the no sugar sweeteners o...  \n",
       "568331  These are delicious organic hard candies. I on...  \n",
       "568345  These ladyfingers were fresh and delicious!  E...  \n",
       "568361  *****<br />St. Dalfour's wonderful Certified O...  \n",
       "568367  Quite simply one of the best Earl Grey's I've ...  \n",
       "\n",
       "[24545 rows x 10 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape\n",
    "filtered_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24545, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting data according to ProfileName\n",
    "sorted_data=filtered_df.sort_values('ProfileName', axis=0, ascending=True)\n",
    "sorted_data.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16068, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing duplicate entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16068, 10)\n"
     ]
    }
   ],
   "source": [
    "#keep entries where helfulness numerator is higher than denominator\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score\n",
       "positive    14011\n",
       "negative     2057\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of positive vs. negative reviews\n",
    "final['Score'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words\n",
    "count_vect = CountVectorizer()\n",
    "final = final.sort_values(by='Time')\n",
    "final_counts = count_vect.fit_transform(final['Text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method spmatrix.get_shape of <16068x27413 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1066790 stored elements in Compressed Sparse Row format>>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts.get_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I don't know why anyone would ever use those little liquid food colors again after trying these pastes. The colors are more intense, and you can easily blend lovely shades for your icings. <p>Martha Stewart shows wonderful seasonal cookies from time to time on her TV show. A simple eggwhite-sugar icing on cookies in exciting colors makes such a wonderful table decoration as well as great dessert for parties, teas and other events. These paste colors are a must if you like to make frosted cookies or party cakes. <p>And these are especially fun if you have kids. A cookie-icing contest is a fun event for a birthday party, Christmas party or just a rainy afternoon.\n"
     ]
    }
   ],
   "source": [
    "#Text Preprocessing: Stemming, stop-word removal and Lemmatization\n",
    "#find sentences containing HTML tags\n",
    "import re\n",
    "\n",
    "i=0;\n",
    "for sent in final['Text'].values:\n",
    "    if(len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "i += 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') # initilizes snowball stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weren', \"should've\", \"didn't\", 'yourselves', 'my', 'mustn', 'over', 'ourselves', 'no', 'then', 'it', 'same', 'hers', 'mightn', 'does', \"isn't\", 'doing', 'both', 'any', \"mustn't\", 'of', 'once', \"she's\", 'his', 'those', 'll', 've', \"won't\", 'who', 'a', 'or', 'for', 'about', 're', 'am', 'when', 'nor', \"it's\", 't', \"that'll\", 'ours', 'which', 'too', 'ain', \"don't\", 'him', 'don', 'shan', 'is', 'your', 'you', 's', 'down', 'he', 'under', \"wouldn't\", 'so', 'we', 'by', 'through', 'where', 'has', 'needn', \"doesn't\", 'this', 'than', 'shouldn', 'were', 'such', 'be', 'her', 'as', 'theirs', \"you'd\", 'are', 'while', \"wasn't\", 'in', 'after', 'y', 'further', 'wasn', 'its', \"shouldn't\", 'm', 'do', 'had', 'again', 'they', 'our', 'and', 'if', 'before', 'now', \"shan't\", 'some', \"aren't\", 'these', 'from', 'during', 'just', 'more', 'below', 'was', 'she', 'only', 'between', 'into', 'but', 'hadn', \"hadn't\", 'himself', 'at', 'wouldn', 'on', 'whom', 'here', 'not', 'that', 'what', 'the', 'ma', 'me', 'off', 'them', 'most', 'haven', 'didn', 'aren', 'won', 'doesn', 'their', 'have', 'an', \"hasn't\", 'to', 'themselves', 'i', 'very', 'can', \"couldn't\", 'yours', 'there', 'myself', \"you'll\", 'all', 'until', 'did', \"needn't\", 'isn', 'will', 'couldn', \"you're\", 'out', \"mightn't\", 'up', 'hasn', 'own', 'been', 'd', 'yourself', 'herself', 'why', 'because', 'how', 'other', 'should', 'o', 'each', \"you've\", 'with', \"haven't\", 'above', \"weren't\", 'itself', 'against', 'being', 'few', 'having'}\n",
      "*************************************\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "def cleanhtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return cleaned\n",
    "print(stop)\n",
    "print('*************************************')\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "strl= ' '\n",
    "final_string=[]\n",
    "all_positive_words=[]\n",
    "all_negative_words=[]\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):\n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive':\n",
    "                        \n",
    "                        all_positive_words.append(s)\n",
    "                    if (final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string #adding a coln of CleanendText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common positive words :  [(b'like', 8928), (b'flavor', 7809), (b'tast', 7770), (b'good', 6960), (b'tea', 6836), (b'use', 5916), (b'one', 5907), (b'great', 5155), (b'love', 4868), (b'product', 4758), (b'make', 4706), (b'tri', 4567), (b'food', 4146), (b'get', 3999), (b'coffe', 3781), (b'also', 3261), (b'would', 3260), (b'eat', 3213), (b'realli', 3178), (b'time', 2908)]\n",
      "Most common negative words :  [(b'tast', 1409), (b'like', 1343), (b'product', 1044), (b'flavor', 869), (b'one', 862), (b'food', 754), (b'would', 729), (b'tri', 698), (b'good', 583), (b'eat', 556), (b'use', 541), (b'buy', 530), (b'even', 503), (b'get', 502), (b'dont', 476), (b'coffe', 467), (b'tea', 462), (b'order', 454), (b'dog', 451), (b'much', 432)]\n"
     ]
    }
   ],
   "source": [
    "#Bi-Grams and n-Grams\n",
    "#analyze frequency distribution of words in positive/negative reviews\n",
    "freq_dist_positive=nltk.FreqDist(all_positive_words)\n",
    "freq_dist_negative=nltk.FreqDist(all_negative_words)\n",
    "print(\"Most common positive words : \",freq_dist_positive.most_common(20))\n",
    "print(\"Most common negative words : \",freq_dist_negative.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF_IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(final['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16068, 422676)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tf_idf.get_shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422676"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf_idf_vect.get_feature_names_out()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daughter reaction', 'daughter really', 'daughter reports',\n",
       "       'daughter said', 'daughter seems', 'daughter she',\n",
       "       'daughter simply', 'daughter specifically', 'daughter spit',\n",
       "       'daughter started'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(final_tf_idf[3,:].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "top_tfidf = top_tfidf_feats(final_tf_idf[1,:].toarray()[0],features,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>0.277714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read it</td>\n",
       "      <td>0.269347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would read</td>\n",
       "      <td>0.218802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this book</td>\n",
       "      <td>0.209923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read</td>\n",
       "      <td>0.155248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>0.117672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>either lost</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>attic and</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>somewhere probably</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>at garage</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>girl and</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>probably up</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>another copy</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>copy at</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>two copies</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mine when</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>been either</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>niece recommend</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>or given</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bedtime book</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the attic</td>\n",
       "      <td>0.109401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>as bedtime</td>\n",
       "      <td>0.104961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lost or</td>\n",
       "      <td>0.104961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attic</td>\n",
       "      <td>0.104961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>given away</td>\n",
       "      <td>0.104961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature     tfidf\n",
       "0                 book  0.277714\n",
       "1              read it  0.269347\n",
       "2           would read  0.218802\n",
       "3            this book  0.209923\n",
       "4                 read  0.155248\n",
       "5                   it  0.117672\n",
       "6          either lost  0.109401\n",
       "7            attic and  0.109401\n",
       "8   somewhere probably  0.109401\n",
       "9            at garage  0.109401\n",
       "10            girl and  0.109401\n",
       "11         probably up  0.109401\n",
       "12        another copy  0.109401\n",
       "13             copy at  0.109401\n",
       "14          two copies  0.109401\n",
       "15           mine when  0.109401\n",
       "16         been either  0.109401\n",
       "17     niece recommend  0.109401\n",
       "18            or given  0.109401\n",
       "19        bedtime book  0.109401\n",
       "20           the attic  0.109401\n",
       "21          as bedtime  0.104961\n",
       "22             lost or  0.104961\n",
       "23               attic  0.104961\n",
       "24          given away  0.104961"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "import gensim\n",
    "list_of_sent = []\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence = []\n",
    "    # Perform text cleaning here\n",
    "    sent = cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_word in cleanpunc(w).split():\n",
    "            if cleaned_word.isalpha():  # Corrected variable name\n",
    "                filtered_sentence.append(cleaned_word.lower())  # Corrected variable name\n",
    "    list_of_sent.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know why anyone would ever use those little liquid food colors again after trying these pastes. The colors are more intense, and you can easily blend lovely shades for your icings. <p>Martha Stewart shows wonderful seasonal cookies from time to time on her TV show. A simple eggwhite-sugar icing on cookies in exciting colors makes such a wonderful table decoration as well as great dessert for parties, teas and other events. These paste colors are a must if you like to make frosted cookies or party cakes. <p>And these are especially fun if you have kids. A cookie-icing contest is a fun event for a birthday party, Christmas party or just a rainy afternoon.\n",
      "**********************************************************\n",
      "['i', 'dont', 'know', 'why', 'anyone', 'would', 'ever', 'use', 'those', 'little', 'liquid', 'food', 'colors', 'again', 'after', 'trying', 'these', 'pastes', 'the', 'colors', 'are', 'more', 'intense', 'and', 'you', 'can', 'easily', 'blend', 'lovely', 'shades', 'for', 'your', 'icings', 'martha', 'stewart', 'shows', 'wonderful', 'seasonal', 'cookies', 'from', 'time', 'to', 'time', 'on', 'her', 'tv', 'show', 'a', 'simple', 'icing', 'on', 'cookies', 'in', 'exciting', 'colors', 'makes', 'such', 'a', 'wonderful', 'table', 'decoration', 'as', 'well', 'as', 'great', 'dessert', 'for', 'parties', 'teas', 'and', 'other', 'events', 'these', 'paste', 'colors', 'are', 'a', 'must', 'if', 'you', 'like', 'to', 'make', 'frosted', 'cookies', 'or', 'party', 'cakes', 'and', 'these', 'are', 'especially', 'fun', 'if', 'you', 'have', 'kids', 'a', 'contest', 'is', 'a', 'fun', 'event', 'for', 'a', 'birthday', 'party', 'christmas', 'party', 'or', 'just', 'a', 'rainy', 'afternoon']\n"
     ]
    }
   ],
   "source": [
    "print(final['Text'].values[0])\n",
    "print(\"**********************************************************\")\n",
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector dimensions: 50\n"
     ]
    }
   ],
   "source": [
    "w2v_model = gensim.models.Word2Vec(list_of_sent, min_count=5, vector_size=50, workers=4)\n",
    "# Get the dimensions of word vectors\n",
    "vector_size = w2v_model.vector_size\n",
    "print(f\"Word vector dimensions: {vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9326\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.key_to_index)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yummy', 0.8432245254516602), ('satisfying', 0.8397105932235718), ('delicious', 0.825793981552124), ('filling', 0.8240694403648376), ('flavorful', 0.7353563904762268), ('versatile', 0.7291220426559448), ('moist', 0.7093454003334045), ('crunchy', 0.7065858840942383), ('nice', 0.7045647501945496), ('nutritious', 0.6815524101257324)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = w2v_model.wv.most_similar('tasty')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prefer', 0.6275021433830261), ('mean', 0.6218447089195251), ('think', 0.6181060075759888), ('know', 0.5722044706344604), ('love', 0.5532277822494507), ('enjoy', 0.5434105396270752), ('miss', 0.5302862524986267), ('expect', 0.528601884841919), ('notice', 0.5199308395385742), ('gross', 0.5147050619125366)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = w2v_model.wv.most_similar('like')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming count_vect_feat is a numpy array\n",
    "count_vect_feat = count_vect.get_feature_names_out()  # list of words in BoW\n",
    "index_of_like = np.where(count_vect_feat == 'like')[0][0]  # Get the first index where 'like' occurs\n",
    "print(index_of_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
